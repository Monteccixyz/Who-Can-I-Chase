{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "section-1-loading",
   "metadata": {},
   "source": [
    "# eBird Data Exploration\n",
    "\n",
    "This notebook explores the eBird dataset for Spain to understand its structure and prepare for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-header",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "We have two datasets:\n",
    "- `sample.csv`: A small sample for quick exploration\n",
    "- `ebird_spain_2020-2025.txt`: The full Spain dataset (~32M rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample dataset\n",
    "sample_df = pd.read_csv(\"../data/raw/sample.csv\", delimiter=\"\\t\")\n",
    "print(f\"Sample shape: {sample_df.shape}\")\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-full-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the full dataset structure (first 100 rows)\n",
    "full_df = pd.read_csv(\"../data/raw/ebird_spain_2020-2025.txt\", delimiter=\"\\t\", nrows=100)\n",
    "print(f\"Columns: {len(full_df.columns)}\")\n",
    "print(full_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "count-full-rows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total rows in the full dataset\n",
    "with open(\"../data/raw/ebird_spain_2020-2025.txt\", \"r\") as f:\n",
    "    row_count = sum(1 for _ in f)\n",
    "print(f\"Total rows in full dataset: {row_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2-header",
   "metadata": {},
   "source": [
    "## 2. Column Exploration\n",
    "\n",
    "The eBird dataset has 53 columns. For our ML model, we need a subset focused on:\n",
    "- **What**: Species identification (COMMON NAME, SCIENTIFIC NAME)\n",
    "- **Where**: Location (LATITUDE, LONGITUDE, STATE)\n",
    "- **When**: Time (OBSERVATION DATE, TIME OBSERVATIONS STARTED)\n",
    "- **How**: Observation method (OBSERVATION TYPE, DURATION MINUTES, EFFORT DISTANCE KM)\n",
    "- **Completeness**: Whether all species were reported (ALL SPECIES REPORTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cols-subset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we'll use for the model\n",
    "cols_to_keep = [\n",
    "    \"COMMON NAME\",\n",
    "    \"SCIENTIFIC NAME\",\n",
    "    \"STATE\",\n",
    "    \"LATITUDE\",\n",
    "    \"LONGITUDE\",\n",
    "    \"OBSERVATION DATE\",\n",
    "    \"TIME OBSERVATIONS STARTED\",\n",
    "    \"OBSERVATION TYPE\",\n",
    "    \"DURATION MINUTES\",\n",
    "    \"EFFORT DISTANCE KM\",\n",
    "    \"ALL SPECIES REPORTED\",\n",
    "    \"SAMPLING EVENT IDENTIFIER\"\n",
    "]\n",
    "\n",
    "# Load a larger sample with just these columns\n",
    "df = pd.read_csv(\n",
    "    \"../data/raw/ebird_spain_2020-2025.txt\",\n",
    "    delimiter=\"\\t\",\n",
    "    usecols=cols_to_keep,\n",
    "    nrows=1_000_000\n",
    ")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cols-observation-types",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What observation types exist?\n",
    "print(\"Observation Types:\")\n",
    "print(df[\"OBSERVATION TYPE\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-header",
   "metadata": {},
   "source": [
    "## 3. Data Quality\n",
    "\n",
    "Check for missing values and data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "print(\"Null counts per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-nulls-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nulls in DURATION_MINUTES and EFFORT_DISTANCE_KM are expected:\n",
    "# - Stationary protocols don't have distance\n",
    "# - Incidental observations don't have duration or distance\n",
    "\n",
    "print(\"\\nNull analysis by observation type:\")\n",
    "for obs_type in df[\"OBSERVATION TYPE\"].unique():\n",
    "    subset = df[df[\"OBSERVATION TYPE\"] == obs_type]\n",
    "    print(f\"\\n{obs_type}:\")\n",
    "    print(f\"  Duration nulls: {subset['DURATION MINUTES'].isnull().sum()} / {len(subset)}\")\n",
    "    print(f\"  Distance nulls: {subset['EFFORT DISTANCE KM'].isnull().sum()} / {len(subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-complete-checklists",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL SPECIES REPORTED indicates complete checklists\n",
    "# These are valuable for generating negative observations (species NOT seen)\n",
    "print(\"Complete checklists (ALL SPECIES REPORTED):\")\n",
    "print(df[\"ALL SPECIES REPORTED\"].value_counts())\n",
    "print(f\"\\n{df['ALL SPECIES REPORTED'].mean() * 100:.1f}% are complete checklists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-header",
   "metadata": {},
   "source": [
    "## 4. Scope Decision\n",
    "\n",
    "### Region: Andalucía\n",
    "\n",
    "We're limiting the scope to Andalucía region for several reasons:\n",
    "1. **API Rate Limits**: Open-Meteo's historical weather API has daily limits\n",
    "2. **Manageable Scale**: Fewer coordinates to fetch weather for\n",
    "3. **Rich Biodiversity**: Andalucía has diverse habitats and bird species\n",
    "\n",
    "### Weather Data: 2025 Only\n",
    "\n",
    "Originally planned 5 years (2020-2025), but reduced to 1 year (2025) due to:\n",
    "1. **API Constraints**: 10k calls/day limit\n",
    "2. **Faster Iteration**: Can train initial models sooner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scope-andalucia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available regions (STATE column)\n",
    "print(\"Observations by region:\")\n",
    "print(df[\"STATE\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scope-andalucia-coords",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique coordinates in Andalucía?\n",
    "andalucia_df = df[df[\"STATE\"] == \"Andalucía\"].copy()\n",
    "andalucia_df[\"lat_rounded\"] = andalucia_df[\"LATITUDE\"].round(1)\n",
    "andalucia_df[\"lon_rounded\"] = andalucia_df[\"LONGITUDE\"].round(1)\n",
    "\n",
    "unique_coords = andalucia_df[[\"lat_rounded\", \"lon_rounded\"]].drop_duplicates()\n",
    "print(f\"Unique coordinates in Andalucía (0.1 degree precision): {len(unique_coords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scope-date-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range in the data\n",
    "print(f\"Date range: {df['OBSERVATION DATE'].min()} to {df['OBSERVATION DATE'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
